---
title: "[CNN] 1. Convolutional Neural Network (1)"
excerpt: "CNN μ— λ€ν•΄ μ•μ•„λ³΄μ"

categories: "cnn"
tags:
    - deep learning
    - computer vision
    - CNN
toc: true  
toc_sticky: true
toc_label: "Contents In Page"
author_profile: true
use_math: true

date: 2024-04-10
---

## **CNN(Convolutional Neural Network)**

### λ“±μ¥λ°°κ²½
- 

### Convolution
- μ»¨λ³Όλ£¨μ…μ€ μ‹ νΈ μ²λ¦¬μ—μ„ μ‚¬μ©λλ κ°λ…μ΄λ‹¤. λ‘ κ°μ ν•¨μλ¥Ό μ μ„μ–΄μ£Όλ” λ°©λ²•, μ¦‰ ν•©μ„±κ³±μΌλ΅ μ •μλλ‹¤.
- μ‹ νΈμ²λ¦¬μ—μ„ μ‹μ¤ν…μ μ¶λ ¥μ„ κµ¬ν•  λ• μ“°λ” ν•λ‚μ μ—°μ‚°μΈλ°, λ‘ κ°€μ§€ μ‹ νΈκ°€ κ²Ήμ³μ§€λ” λ¶€λ¶„μ λ„“μ΄(μ λ¶„)λ΅ κµ¬ν•΄μ§„λ‹¤.
- 
- μ»¨λ³Όλ£¨μ…μ€ μ‹ νΈ μ²λ¦¬μ—μ„ μ‚¬μ©λλ κ°λ…. λ‘ κ°μ ν•¨μλ¥Ό μ μ„μ–΄μ£Όλ” λ°©λ²•, operator λ΅ μ •μλ κ²ƒ.

![Untitled](/assets/images/DL_basic/Untitled%2026.png)

β†’ μ΄λ―Έμ§€μ—μ„ λ³΄λ©΄, $I$λ” μ „μ²΄ μ΄λ―Έμ§€ κ³µκ°„, $K$λ” μ°λ¦¬κ°€ μ μ©ν•κ³ μ ν•λ” ν•„ν„°μ λ¨μ–‘

- μ»¨λ³Όλ£¨μ… μ—°μ‚°

![Untitled](/assets/images/DL_basic/Untitled%2027.png)

- μ»¨λ³Όλ£¨μ… μ—°μ‚°μ μλ―Έ? μ°λ¦¬κ°€ μ μ©ν•κ³ μ ν•λ” ν•„ν„°μ λ¨μ–‘μ— λ”°λΌμ„ κ°™μ€ μ΄λ―Έμ§€μ— λ€ν•΄μ„ convolution output μ΄ λ‹¬λΌμ§. λΈ”λ¬, κ°•μ΅°, μ™Έκ³½μ„  λ“±λ“±
- feature μ channel μλ” μ–΄λ–»κ² λ‚μ¬κΉ? μ»¨λ³Όλ£¨μ… ν•„ν„°κ°€ μ—¬λ¬κ° μλ‹¤κ³  λ³Ό μ μλ” κ²ƒ. μ»¨λ³Όλ£¨μ… ν•„ν„°κ°€ 1κ° μμΌλ©΄ μ•„μ›ƒν’‹μ μ±„λ„μ€ 1. 4κ°κ°€ μμΌλ©΄ μ±„λ„μ€ 4

β†’ κ·Έλμ„ μ°λ¦¬κ°€ μΈν’‹ μ±„λ„κ³Ό μ•„μ›ƒν’‹(μ»¨λ³Όλ£¨μ… ν”Όμ³λ§µ)μ μ±„λ„μ„ μ•λ©΄, μ—¬κΈ°μ— μ μ©λλ” μ»¨λ³Όλ£¨μ… ν”Όμ³μ ν¬κΈ° μ—­μ‹ κ³„μ‚°ν•  μ μμ.

β†’ RGB μ΄λ―Έμ§€λ” 3κ°μ μ±„λ„(Red, Green, Blue)μ„ κ°€μ§€λ―€λ΅, μ΄ μ΄λ―Έμ§€μ— μ μ©λλ” μ»¨λ³Όλ£¨μ… ν•„ν„°λ„ 3κ°μ μ±„λ„μ„ κ°€μ Έμ•Ό ν•λ‹¤. μ΄λ ‡κ² ν•μ—¬ κ° ν•„ν„°μ μ±„λ„μ΄ μ…λ ¥ μ΄λ―Έμ§€μ ν•΄λ‹Ή μ±„λ„κ³Ό μ—°μ‚°λλ‹¤. κ·Έ ν›„ λ¨λ“  μ±„λ„μ κ²°κ³Όκ°€ ν•©μ³μ Έ μµμΆ… μ¶λ ¥ νΉμ„± λ§µ(feature map)μ„ μƒμ„±ν•λ‹¤.

β†’ μ»¨λ³Όλ£¨μ… λ μ΄μ–΄μ—μ„ ν•„ν„°(λλ” μ»¤λ„)μ κ°μλ” μ¶λ ¥ λ°μ΄ν„°μ μ±„λ„ μλ¥Ό κ²°μ •ν•©λ‹λ‹¤. κ° ν•„ν„°λ” μ…λ ¥ λ°μ΄ν„°μ— λ…λ¦½μ μΌλ΅ μ μ©λλ©°, κ° ν•„ν„°μ μ¶λ ¥μ€ μ¶λ ¥ λ°μ΄ν„°μ ν•λ‚μ μ±„λ„μ„ ν•μ„±ν•λ‹¤.

![Untitled](/assets/images/DL_basic/Untitled%2028.png)

- μ»¨λ³Όλ£¨μ… ν•„ν„°κ°€ μ—¬λ¬κ° μμ„ μλ„ μμ. λ‹¨, ν• λ² μ»¨λ³Όλ£¨μ…μ„ κ±°μΉκ³  λ‚λ©΄ κ·Έ λ‹¤μμ—λ” non-linear activation μ΄ λ“¤μ–΄κ°€κ² λ¨. μ¦‰, μ…λ ¥ μ΄λ―Έμ§€(32*32*3)κ°€ μ»¨λ³Όλ£¨μ… ν•„ν„°(4 5*5*3)λ¥Ό κ±°μ³μ„ λ‚μ¨ μ»¨λ³Όλ£¨μ… ν”Όμ³λ§µ(28*28*4)μ κ° element λ³„λ΅ activation func νΉμ€ non-linear activation μ„ κ±°μΉ¨(ReLU λ“±).

![Untitled](/assets/images/DL_basic/Untitled%2029.png)

- μ»¨λ³Όλ£¨μ… ν•„ν„°μ μ±„λ„μ€ λ‚΄κ°€ μ§€κΈ μ»¨λ³Όλ£¨μ…μ„ ν•λ” feature(μΈν’‹ μ΄λ―Έμ§€)μ dimensionμ΄ λ¨.
- ν•­μƒ μ§‘μ¤‘ν•΄μ„ λ΄μ•Ό ν•  κ²ƒμ€ μ΄ μ—°μ‚°μ„ μ •μν•λ”λ° ν•„μ”ν• νλΌλ―Έν„°μ μ«μλ¥Ό μ μƒκ°ν•΄μ•Ό ν•¨.
- μ»¨λ³Όλ£¨μ… μ»¤λ„μ size * μΈν’‹ μ΄λ―Έμ§€μ μ±„λ„ * μ•„μ›ƒν’‹ μ±„λ„ μ«μ
- μΌλ°μ μΈ CNN μ€ μ»¨λ³Όλ£¨μ… λ μ΄μ–΄, pooling layer, fully connected layer λ“±μΌλ΅ μ΄λ£¨μ–΄μ Έ μμ.
- Convolution and pooling layers : feature extraction. μ΄λ―Έμ§€μ—μ„ μ μ©ν• μ •λ³΄λ¥Ό μ¶”μ¶
- Fully connected layer : decision making. λ¶„λ¥λ¥Ό ν•κ±°λ‚ νκ·€λ¥Ό ν•΄μ„ λ‚΄κ°€ μ›ν•λ” μ¶λ ¥κ°’μ„ μ–»μ–΄μ£Όλ” κ²ƒ.
- μ΄λ ‡κ² λ§λ“¤μ–΄μ§„ κ²ƒμ΄ μΌλ°μ μΈ CNN. μµκ·Ό λ“¤μ–΄μ„ λ’·λ‹¨μ FC κ°€ μ μ  μµμ†ν™”μ‹ν‚¤λ” μ¶”μ„Έ. μ™λƒλ©΄ νλΌλ―Έν„° μ«μμ— dependent ν•κ² λ¨.
- λ‚΄κ°€ ν•™μµν•κ³ μ ν•λ” μ–΄λ–¤ λ¨λΈμ νλΌλ―Έν„°μ μ«μ. λ‚΄κ°€ ν•™μµν•΄μ•Ό ν•λ” νλΌλ―Έν„° μ«μκ°€ λμ–΄λ‚  μλ΅ ν•™μµμ΄ μ–΄λ µκ³  μΌλ°ν™” μ„±λ¥μ΄ λ–¨μ–΄μ§„λ‹¤κ³  μ•λ ¤μ Έ μμ. μ¦‰ λ‚΄κ°€ μ•„λ¬΄λ¦¬ ν•™μµμ„ μ μ‹μΌλ„ μ΄ λ¨λΈμ„ λ°°ν¬ν–μ„ λ• μ„±λ¥μ΄ μ•λ‚μ¤λ” κ²ƒ.

β†’ CNN μ΄ λ°μ „ν•λ” λ°©ν–¥μ€ κ°™μ€ λ¨λΈμ„ λ§λ“¤κ³  μµλ€ν• λ¨λΈμ„ deep ν•κ² κ°€μ Έκ°€μ§€λ§ λ™μ‹μ— νλΌλ―Έν„° μ«μλ¥Ό μ¤„μ΄λ”λ° μ§‘μ¤‘ν•κ² λ¨. μ΄λ¥Ό μ„ν• ν…ν¬λ‹‰λ“¤μ΄ λ§μ. κ³„μ† κ°•μ΅°ν•΄μ•Ό ν•λ” κ²ƒμ€, μ–΄λ–¤ λ‰΄λ΄ λ„¤νΈμ›ν¬ μ•„ν‚¤ν…μ³λ¥Ό λ΄¤μ„ λ• λ„¤νΈμ›ν¬μ λ μ΄μ–΄ λ³„λ΅ λ‡ κ°μ νλΌλ―Έν„°λ΅ μ΄λ£¨μ–΄μ Έ μκ³ , μ „μ²΄ νλΌλ―Έν„° μ«μκ°€ λ‡ κ° μΈμ§€λ¥Ό ν•­μƒ λ‡ κ° μΈμ§€ λ³΄λ” κ²ƒ. κ·Έ κ°μ„ κ°€μ§€λ” κ²ƒμ΄ μ¤‘μ”ν•κ² λ¨.

- μ–΄λ–¤ λ‰΄λ΄ λ„¤νΈμ›ν¬μ— λ€ν•΄μ„, νλΌλ―Έν„°κ°€ λ‡ κ°μΈμ§€λ¥Ό μ†μΌλ΅ κ³„μ‚°ν•΄ λ³΄λ” κ²ƒμ΄ μΆ‹μ.
- patch size/stride, output size, params
- Stride λ€?
- λ„“κ² κ±·λ”λ‹¤ λΌλ” κ²ƒ. stride κ°€ 1μ΄λΌλ” κ²ƒμ€ μ»¤λ„(μ»¨λ³Όλ£¨μ… ν•„ν„°)μ„ λ§¤ ν”½μ…€λ§λ‹¤ μ°κ³  λ°”λ΅ ν• ν”½μ…€ μ®κ²¨μ„ μ°λ” κ²ƒ. strideκ°€ 2μ΄λ©΄ ν•„ν„°λ¥Ό ν•λ‚ μ°κ³  λ°”λ΅ μ†μΌλ΅ μ®κΈ°λ” κ²ƒμ΄ μ•„λ‹λΌ 2μΉΈ μ®κΈ°λ” κ²ƒ. λ‚΄κ°€ μ»¨λ³Όλ£¨μ… ν•„ν„°λ¥Ό μ–Όλ§λ‚ dense νΉμ€ sparse ν•κ² μ°μ„ κ²ƒμ΄λƒλ¥Ό λ§ν•κ² λλ” κ²ƒ.

![μ΄ κ·Έλ¦Όμ—μ„λ” 1D Convolution](/assets/images/DL_basic/Untitled%2030.png)

μ΄ κ·Έλ¦Όμ—μ„λ” 1D Convolution

- 2D λ΅ κ°€λ©΄ stride μ νλΌλ―Έν„°κ°€ 2κ°κ°€ λ¨. width, height λ°©ν–¥μΌλ΅.
- Padding μ΄λ€?
- μΌλ°μ μΈ μ»¨λ³Όλ£¨μ… μ„ λλ¦¬λ©΄ λ°”μ΄λ”λ¦¬ μ •λ³΄κ°€ λ²„λ ¤μ§. λ‚΄κ°€ κ°€μ§„ μ΄λ―Έμ§€μ κ°€μ¥ κ°€μ¥μλ¦¬λ¥Ό μ°μ„ μ μ—†μ. μ»¨λ³Όλ£¨μ… ν•„ν„°κ°€ μ‚μ Έλ‚μ΄. κ·Έλμ„ κ°€μ¥μλ¦¬λ¥Ό μƒλ΅ λ§λ“¤μ–΄μ£Όλ” κ²ƒμ΄ padding. μΌλ°μ μΌλ΅ 0-padding μ€ κ·Έ λ§λ€λ” κ°’μ΄ 0μΈ κ²ƒ.
- μ¦‰ ν¨λ”©μ„ ν•΄μ£Όλ©΄ μΈν’‹κ³Ό μ•„μ›ƒν’‹μ dimension μ΄ λ‘κ°™κ² λ¨.

![Untitled](/assets/images/DL_basic/Untitled%2031.png)

- μ μ ν• ν¬κΈ°μ ν¨λ”©κ³Ό stride κ°€ 1μ΄λ©΄ μ–΄λ–¤ μ…λ ¥κ³Ό convolution operator μ μ¶λ ¥μΌλ΅ λ‚μ¤λ” μ»¨λ³Όλ£¨μ… ν”Όμ³λ§µμ dimesion μ΄ κ°™μ•„μ§€λ” κ²ƒμ„ μ• μ μμ.
- 3*3 μΌ λ•λ” ν¨λ”©μ΄ 1, 5*5 μΌ λ•λ” ν¨λ”©μ΄ 2, 7*7 μΌ λ•λ” ν¨λ”©μ΄ 3μ΄ ν•„μ”ν•¨.
`kernel size // 2` β†’ μ μ ν• ν¨λ”©κ³Ό stride κ°€ 1μ΄λ©΄ ν•­μƒ μ…λ ¥κ³Ό μ¶λ ¥μ΄ κ°™λ‹¤!
- μ»¨λ³Όλ£¨μ… μ—°μ‚°μ„ ν•  λ• λ‚΄κ°€ μ›ν•λ” μ¶λ ¥κ°’μ— λ§μ¶°μ„ μ λ΅ ν¨λ”©κ³Ό stride λ¥Ό μ¤„ μ μμ.

![Untitled](/assets/images/DL_basic/Untitled%2032.png)

- νλΌλ―Έν„° μ«μ κ³„μ‚°.

<aside>
π’΅ λ¨Όμ €, Convolution μ—°μ‚° ν›„ Output image μ ν¬κΈ°(ν…μ„ ν¬κΈ°)λ”
(input size + (2*padding)- filter size)/stride + 1 μ΄λ‹¤.

![Untitled](/assets/images/DL_basic/Untitled%2033.png)

Pooling μ—°μ‚° ν›„ output image μ ν¬κΈ°(ν…μ„ ν¬κΈ°)λ”

![$I$ : input size, $P_s$ : Pooling size, $S$ = stride of convolution operation](/assets/images/DL_basic/Untitled%2034.png)

$I$ : input size, $P_s$ : Pooling size, $S$ = stride of convolution operation

</aside>

![Untitled](/assets/images/DL_basic/Untitled%2035.png)

- μ»¨λ³Όλ£¨μ… ν”Όμ³λ§µ(μ—°μ‚°μΌλ΅ λ‚μ¤λ” κ²ƒ)μ ν•λ‚μ μ±„λ„(ν• κ²Ή)μ„ λ§λ“¤κΈ° μ„ν•΄μ„λ”, λ‚΄κ°€ μ»¨λ³Όλ£¨μ… ν•κ³  μ‹¶μ€ μ»¤λ„μ special dimension(μ„μ—μ„λ” 3*3) μ΄ μκ³ . μλ™μΌλ΅ κ°κ°μ μ»¤λ„μ μ±„λ„ ν¬κΈ°λ” λ‚΄κ°€ κ°€μ§€κ³  μλ” μΈν’‹ dimκ³Ό λ‘κ°™κ² λ¨. μ¦‰ ν•λ‚μ μ»¨λ³Όλ£¨μ… ν•„ν„°(μ»¤λ„)μ μ±„λ„μ€ μΈν’‹ μ΄λ―Έμ§€μ™€ κ°™μ.
- μ„ μμ—μ„ μ»¤λ„μ special dimension μ΄ 3*3 μ΄κ³ , μΈν’‹ μ΄λ―Έμ§€μ special dimension μ΄ 40*50 μΌ λ•, λ‘ κ°μ μ±„λ„ μλ” κ°™κ³ , padding μ΄ 1, stride κ°€ 1 μ΄λ©΄ μ…λ ¥μ΄λ―Έμ§€μ™€ κ°™μ€ special dimension μ μ•„μ›ƒν’‹ μ¦‰ μ»¨λ³Όλ£¨μ… ν”Όμ³κ°€ 1κ²Ή λ‚μ¤κ² λ¨(μ¦‰ μ±„λ„μ΄ 1). κ·Έλ¬λ‚ μ°λ¦¬κ°€ κ¶κ·Ήμ μΌλ΅ μ›ν•λ” μ•„μ›ƒν’‹μ μ±„λ„μ€ 64 μ΄κΈ° λ•λ¬Έμ—, μ»¨λ³Όλ£¨μ… ν•„ν„°(μ»¤λ„)κ°€ 64κ° ν•„μ”ν• κ²ƒ. λ”°λΌμ„ ν•„μ”ν• νλΌλ―Έν„° μ«μλ” μ•„λμ™€ κ°™μ΄ λλ‹¤.

$$
3 \times 3 \times 128 \times 64 = 73,728
$$

- padding μ΄λ‚ stride λ” νλΌλ―Έν„° μ«μμ™€λ” λ¬΄κ΄€ν•¨. CNN μ—μ„ ν•λ‚μ λ μ΄μ–΄μ νλΌλ―Έν„° μ«μλ” μ¤λ΅μ§€ λ‚΄κ°€ convolution operation ν•λ” ν•„ν„° νΉμ€ μ»¤λ„μ΄ λ‡ κ° μλ”μ§€μ— dependent ν•κΈ° λ•λ¬Έ. λ’¤μ—κ°€μ„ μ΄λ° κ³„μ‚°μ΄ μλ™μΌλ΅ λμ–΄μ•Ό ν•¨. λ„¤νΈμ›ν¬μ νλΌλ―Έν„° μ«μλ¥Ό λ„¤νΈμ›ν¬ λ¨μ–‘λ§ λ΄λ„ κ°μ΄ μƒκ²¨μ•Ό ν•¨. μ΄κ² 10000λ‹¨μ„ μΈμ§€ λ“± λ‹¨μ„ κ°λ…μ—μ„ κ°μ΄ μƒκ²¨μ•Ό ν•λ‹¤λ” κ²ƒ.

β†’ **input, output μ special dimension μ€ μ¤‘μ”μΉ μ•μ. μ΄κ²ƒμ€ νλΌλ―Έν„° μ«μμ™€ μƒκ΄€μ—†μ. μ™λƒλ©΄ conv λ” κ°κ°μ special μ„μΉμ— κ°€ν•΄μ§€λ” convolution ν•„ν„°κ°€ λ™μΌν•κΈ° λ•λ¬Έ.**

- AlexNet μ„ λ³΄μ.

![Untitled](/assets/images/DL_basic/Untitled%2036.png)

β†’ AlexNet μ€ κ·Έ λ‹Ήμ‹ GPU λ©”λ¨λ¦¬ λ¶€μ΅±μΌλ΅ λ¨λΈμ„ 2κ°λλ΅ λ‚λ μ„ μ§„ν–‰ν•¨. κ·Έλμ„ λ§μ§€λ§‰μ— 2κ°€ κ³±ν•΄μ§€λ” κ²ƒ. μ¦‰ μ²«λ²μ§Έ λ μ΄μ–΄μ—μ„ 96 μ±„λ„μ μ»¨λ³Όλ£¨μ… ν”Όμ³λ§µμ„ λ§λ“¤μ–΄μ•Ό ν•λ”λ° 1κ°μ GPU λ©”λ¨λ¦¬ μ‚¬μ΄μ¦μ— λ§μ¶”λ‹¤ λ³΄λ‹ 48λ΅ ν• κ²ƒ.

β†’ μ¤‘μ”ν• κ²ƒμ€, μ—¬κΈ°μ„ λ³΄λ” νλΌλ―Έν„° μ«μλ” μ»¨λ³Όλ£¨μ… λ‹¨κ²μ—μ„λ” λ§μ•„μ•Ό 884k μ„. κ·Έλ°λ° λ’·λ‹¨μ fully connected layer μ— λ“¤μ–΄κ°€λ©΄ λ‹¬λΌμ§.

![Untitled](/assets/images/DL_basic/Untitled%2037.png)

β†’ μ—¬κΈ°μ„ λ¶€ν„°λ” Dense layer μ„. fully connected layer μ μ°¨μ›μ€ μΈν’‹μ νλΌλ―Έν„° κ°μ(λ‰΄λ°μ κ°μ) μ™€ μ•„μ›ƒν’‹μ λ‰΄λ°μ κ°μλ¥Ό κ³±ν• κ²ƒ λ§νΌμ΄λ‹¤. κ°’μ΄ μ—„μ²­ μ»¤μ§€λ” κ²ƒ.

β†’ λΉ¨κ°„μƒ‰ layer κ°€ μ»¨λ³Όλ£¨μ… layer, νλ€μƒ‰ layer κ°€ Dense layer(MLP) μΈλ° νλΌλ―Έν„° μ«μκ°€ μ»¨λ³Όλ£¨μ…μ— λΉ„ν•΄μ„ dense layerμ— λ„μ–΄κ°€λ©΄μ„ κ±°μ 1,000λ°°κ°€ λμ–΄λ‚¨.

β†’ μ™ μ΄λ΄κΉ? λ„¤νΈμ›ν¬κ°€ μΈν’‹μ—μ„ μ•„μ›ƒν’‹μΌλ΅ κ° λ• ν¬κΈ°κ°€ μ—„μ²­ λ³€ν™”λλ” κ²ƒλ„ μ•„λ‹λ°, dense layer κ°€ μΌλ°μ μΌλ΅ ν›¨μ”¬ λ§μ€ νλΌλ―Έν„°λ¥Ό κ°–κ² λλ” μ΄μ λ”, μ»¨λ³Όλ£¨μ… μ—°μ‚°μ΄ κ°κ°μ ν•λ‚μ μ»¤λ„μ΄ λ¨λ“  μ„μΉμ— λ€ν•΄μ„ λ™μΌν•κ² μ μ©λκΈ° λ•λ¬Έ. μ¦‰, μ»¨λ³Όλ£¨μ… μ—°μ‚°μ€ μΌμΆ…μ shared parameter. κ°™μ€ μ»¤λ„μ΄ μ΄λ―Έμ§€μ μ¤λ¥Έμ½, μ™Όμ½, μ„, μ•„λ λ¨λ‘ λ™μΌν•κ² μ μ©λ¨.

β†’ λ‰΄λ΄ λ„¤νΈμ›ν¬λ¥Ό μ„±λ¥μ„ μ¬λ¦¬κΈ° μ„ν•΄μ„λ” νλΌλ―Έν„°λ¥Ό μ¤„μ΄λ” κ²ƒμ΄ μ¤‘μ”. λ”°λΌμ„ λ€λ¶€λ¶„μ νλΌλ―Έν„°κ°€ fc layer μ— λ“¤μ–΄κ°€λ©΄ νλΌλ―Έν„° μκ°€ μ—„μ²­ λμ–΄λ‚κΈ° λ•λ¬Έμ—, λ„¤νΈμ›ν¬κ°€ λ°μ „λλ” μ„±ν–¥μ΄ λ’·λ‹¨μ— μλ” fc layer λ¥Ό μµλ€ν• μ¤„μ΄κ³  μ•λ‹¨μ convolution layerλ¥Ό μµλ€ν• κΉκ² μ“λ” κ²ƒμ΄ μΌλ°μ μΈ νΈλ λ“.

β†’ μ—¬κΈ°μ— μ¶”κ°€λ΅ λ“¤μ–΄κ°€λ” κ²ƒμ΄ 1*1 convolution. μ΄λ¬ν• μ‹λ„λ“¤λ΅ λ‰΄λ΄ λ„¤νΈμ›ν¬μ κΉμ΄λ” κΉμ–΄μ§€μ§€λ§ νλΌλ―Έν„° μ«μλ” μ¤„μ–΄λ“¤κ³  μ„±λ¥μ€ μ¬λΌκ°.

- μ΄λ¥Ό μ„ν•΄ κΈ°λ³Έμ΄ λλ” κ² 1 x 1 convolution
- 1 x 1 convλ” , μ΄λ―Έμ§€μ—μ„ μμ—­μ„ λ³΄μ§€ μ•μ. ν• ν”½μ…€λ§ λ³΄λ” κ²ƒ. μ¦‰ μ±„λ„ λ°©ν–¥μ„ μ¤„μ΄λ” κ²ƒ.
- μ™ ν• κΉ? Dimension reduction. 1x1 conv μ—μ„μ dimension μ€ μ±„λ„μ„ λ§ν•¨.
- μ΄κ²ƒμ μλ―Έλ”, **μ»¨λ³Όλ£¨μ… λ μ΄μ–΄λ¥Ό κΉκ² μ“μΌλ©΄μ„ λ™μ‹μ— νλΌλ―Έν„° μ«μλ¥Ό μ¤„μΌ μ μκ² λ¨. μ¦‰ λμ¤λ” λλ¦¬κ³  νλΌλ―Έν„° μλ” μ¤„μ„.**
- bottleneck architecture κ°€ λ°”λ΅ μ΄ 1x1 conv μ„ μ΄μ©ν•΄μ„ λ„¤νΈμ›ν¬λ¥Ό κΉκ² μ“λ”λ° νλΌλ―Έν„° μ«μλ¥Ό μ¤„μΌ μ μλ” κ²ƒ.

![Untitled](/assets/images/DL_basic/Untitled%2038.png)

- μ‹¤μ  μ΄ 1x1 conv ν…ν¬λ‹‰μ€ κµ‰μ¥ν μμ£Ό μ‚¬μ©λ¨. ResNet, DenseNet λ“± λ‹¤ ν™μ©λ¨.
- λ‚μ¤‘μ— μ»¨λ³Όλ£¨μ… λ μ΄μ–΄μ μ±„λ„ λ””λ©μ…κ³Ό MLPμ νλ“  λ””λ©μ…μ„ μ •ν•΄μ¤„ μ μκ² μ½”λ”©ν•λ©΄ λ„¤νΈμ›ν¬ νλ‹ν•  λ• νΈν•΄μ§.

- Modern CNNs
- AlexNet, ResNet, GoogLeNet, AlexNet, VGGNet, DenseNet
- ISVRC μ—μ„ ν•΄λ§λ‹¤ 1λ“±ν–λ λ¨λΈλ“¤. μ—¬μ „ν μ£Όμν•  κ²ƒμ€ κ°κ° λ„¤νΈμ›ν¬μ νλΌλ―Έν„° μ«μ, λ„¤νΈμ›ν¬μ  λμ¤λ¥Ό λ΄μ•Όν•¨. β†’ λ„¤νΈμ›ν¬μ λμ¤λ” μ μ  κΉμ–΄μ§€κ³ , νλΌλ―Έν„°λ” μ¤„μ–΄κ° κ²ƒμ΄κ³ , μ„±λ¥μ€ μ¬λΌκ°.
- λ„¤νΈμ›ν¬λ¥Ό κΉκ² μ“μΌλ©΄μ„ μ–΄λ–»κ² νλΌλ―Έν„° μλ¥Ό μ¤„μΌ μ μλ”μ§€λ¥Ό κ΄€μ‹¬μκ² λ³΄μ.
- AlexNet(2012)
- μ…λ ¥μ€ κ°™μ§€λ§ λ„¤νΈμ›ν¬κ°€ 2κ°λ΅ λ‚λ‰¨. GPU λ©”λ¨λ¦¬κ°€ λ‹Ήμ‹ λ¶€μ΅±ν–κΈ° λ•λ¬Έ. GPU λ¥Ό μµλ€ν• ν™μ©ν•λ”λ° λ„¤νΈμ›ν¬μ— λ§μ€ νλΌλ―Έν„°λ¥Ό μ§‘μ–΄λ„£κ³  μ‹¶μ–΄μ„ μ΄λ° μ „λµμ„ μ·¨ν• κ²ƒ.
- μΈν’‹ μ΄λ―Έμ§€μ— 11 x 11 μ»¤λ„μ„ μ‚¬μ©ν•¨. νλΌλ―Έν„° μ«μ κ΄€μ μ—μ„ 11x11 μ€ μΆ‹μ€ μ„ νƒμ΄ μ•„λ‹. 11x11 ν•„ν„°λ¥Ό μ‚¬μ©ν•λ©΄ receptive field μ¦‰ ν•λ‚μ μ»¤λ„μ΄ λ³Ό μ μλ” μ΄λ―Έμ§€ μμ—­μ€ μ»¤μ§€μ§€λ§ μƒλ€μ μΌλ΅ λ” λ§μ€ νλΌλ―Έν„°κ°€ ν•„μ”ν•¨.

![Untitled](/assets/images/DL_basic/Untitled%2039.png)

- 8κ°μ λ μ΄μ–΄λ΅ λμ–΄μμ. λ‹Ήμ‹μ—λ” λ”¥ ν–μ.
- Key ideas.
- ReLU λ¥Ό μ‚¬μ©. ν¨κ³Όμ μΈ activation func μ„. activation func μ΄ κ°€μ Έμ•Ό ν•λ” μ²«λ²μ§Έ κ°€μ¥ ν° μ„±μ§μ€ non-linear. ReLUλ” 0μ„ κΈ°μ¤€μΌλ΅ linear ν• λ¶€λ¶„λ„ μμ§€λ§ μ „μ²΄ func μ€ non-linear ν•¨. λν• 0λ³΄λ‹¤ ν΄ λ• κΈ°μΈκΈ°λ„ 1μ΄λΌμ„ κΈ°μΈκΈ° μ†μ‹¤(λ μ΄μ–΄λ¥Ό κΉκ² μ“μ•μ„ λ•)λ„ μ μ—†μ.
- μ„ ν• λ¨λΈμ΄ κ°€μ§€λ” μΆ‹μ€ μ„±μ§μ„ κ°€μ§€κ³  μμ. gradient κ°€ activation κ°’μ΄ μ»¤λ„ gradient λ¥Ό κ·Έλ€λ΅ κ°€μ§ μ μμ.
- λν• μ„ ν• λ¨λΈμ΄ κ°€μ§€λ” μΆ‹μ€ μ„±λ¥μ„ κ°€μ§€κ³  μκΈ° λ•λ¬Έμ— gradient descent κΈ°λ²•λ“¤μ„ μ‚¬μ©ν•΄μ„ ν•™μµμ΄ μ©μ΄ν•¨.
- μ¤‘μ”ν• κ²ƒμ€ κΈ°μΈκΈ° μ†μ‹¤ λ¬Έμ λ¥Ό κ·Ήλ³µν•¨.
- μ΄μ „μ— ν™μ©ν•λ μ‹κ·Έλ¨μ΄λ“, ν•μ΄νΌλ³Όλ¦­ νƒ„μ  νΈλ” 0μ„ κΈ°μ¤€μΌλ΅ κ°’μ΄ μ»¤μ§€λ©΄ slope(gradient) κ°€ μ¤„μ–΄λ“¤κ² λ¨. λ‚΄κ°€ κ°€μ§„ λ‰΄λ°μ κ°’μ΄ 0μ—μ„ λ§μ΄ λ²—μ–΄λ‚κ² λλ©΄, activation μ„ κΈ°μ¤€μΌλ΅ ν•λ” gradient slope λ” 0μ— κ°€κΉκ² λ¨. κ·Έλμ„ κΈ°μΈκΈ° μ†μ‹¤μ΄ μƒκΉ€.
- 2κ°μ GPU μ‚¬μ©
- local response normalization(LRN), overlapping pooling
- LRN μ€ μ–΄λ–¤ μ…λ ¥ κ³µκ°„μ—μ„ response κ°€ λ§μ΄ λ‚μ¤λ” λ‡ κ°λ¥Ό μ£½μ΄λ” κ²ƒ. μµμΆ…μ μΌλ΅ μ›ν•λ” κ²ƒμ€ sparse ν• activation μ΄ λ‚μ¤κΈΈ μ›ν•λ” κ²ƒ. μ§€κΈμ€ λ§μ΄ μ‚¬μ©λμ§€ μ•μ.
- Data augmentation
- Dropout

β†’ μ§€κΈ λ³΄λ©΄ λ‹Ήμ—°ν• κ²ƒλ“¤β€¦ 2012λ…„λ„μ—λ” λ‹Ήμ—°ν•μ§€ μ•μ•μ. μΌλ°μ μΌλ΅ μ μΌ μλλ” κΈ°μ¤€μ„ μ΅μ•λ κ²ƒ.

- VGGNet(2015)

![Untitled](/assets/images/DL_basic/Untitled%2040.png)

- **3x3 convolution ν•„ν„°λ¥Ό μ‚¬μ©.**
- 1x1 μ»¨λ³Όλ£¨μ…μ„ fc layer λ¥Ό μ„ν•΄ μ‚¬μ©ν•¨. κ·Έλ°λ° μ—¬κΈ°μ„λ” νλΌλ―Έν„° μλ¥Ό μ¤„μ΄κΈ° μ„ν•΄ μ‚¬μ©λ κ²ƒμ€ μ•„λ‹.
- Dropout μ„ μ‚¬μ©ν•¨.
- layer μμ— λ”°λΌ VGG16, VGG19
- **μ™ 3x3 convolution?**
- **μ»¨λ³Όλ£¨μ… ν•„ν„°μ ν¬κΈ°λ¥Ό μƒκ°ν•΄λ³΄λ©΄, ν¬κΈ°κ°€ μ»¤μ§€λ©΄μ„ κ°€μ§€λ” μ΄μ μ€ ν•λ‚μ ν•„ν„°μ—μ„ κ³ λ ¤λλ” μΈν’‹μ ν¬κΈ°κ°€ μ»¤μ§„λ‹¤λ” κ²ƒ. κ·Έκ²ƒμ΄ Receptive field λ¥Ό λ§ν•¨. ν•λ‚μ μ»¨λ³Όλ£¨μ… ν”Όμ³λ§µ κ°’μ„ μ–»κΈ° μ„ν•΄μ„ κ³ λ ¤ν•  μ μλ” μ…λ ¥μ spatial dimension μ΄ λ°”λ΅ receptive field.**
- 3x3 conv λ¥Ό 2λ² ν–μ„ λ•, κ°€μ¥ λ§μ§€λ§‰ λ‹¨μ ν•λ‚μ κ°’μ€, μ¤‘κ°„ ν”Όμ³λ§µμ 3x3 μ„ λ³΄κ² λκ³ ,  κ·Έ μ¤‘κ°„ ν”Όμ³λ§µμ ν•λ‚μ κ°’μ€ μΈν’‹μ 3x3 μ„ λ³΄λ” κ²ƒ. μ‚¬μ‹¤μƒ λ§μ§€λ§‰ λ μ΄μ–΄μ ν•λ‚μ κ°’μ€ μΈν’‹ λ μ΄μ–΄μ 5x5 μ ν”½μ…€κ°’μ΄ ν•©μ³μ§„ κ°’μ΄ λ¨. κ·Έλμ„ 3x3 μ΄ λ‘ λ² μ΄λ¤„μ§€λ©΄ receptive field λ” 5x5κ°€ λ¨.
- μ¦‰, **5x5 ν•λ‚ μ‚¬μ©ν•λ” κ²ƒκ³Ό 3x3μ„ λ‘ κ° μ‚¬μ©ν•λ” κ²ƒμ΄ receptive field μΈ΅λ©΄μ—μ„ λ‘κ°™μ.**
κ·Έλ¬λ‚ μ΄ νλΌλ―Έν„° μκ°€ λ‹¬λΌμ§.

![Untitled](/assets/images/DL_basic/Untitled%2041.png)

- μ™ μ΄λ° μΌμ΄ μΌμ–΄λ‚ κΉ?

β†’ λ μ΄μ–΄λ¥Ό λ‘ κ° μ“κ³ , κ·Έλ¬λ‹κΉ νλΌλ―Έν„°κ°€ λ‘ λ°°κ°€ λμ–΄λ‚μ„ 3x3 conv λ¥Ό 2κ° μ“΄ κ² λ” λ§μ€ μκ°€ μμ„ κ²ƒ κ°™μ§€λ§, μ‚¬μ‹¤μƒ 3x3 μ€ κ³±ν•΄λ΄¤μ 9. 2λ°° ν•΄λ΄¤μ 18. 5x5 λ” 25.

β†’ **λ”°λΌμ„ κ°™μ€ receptive field λ¥Ό μ–»λ” κ΄€μ μ—μ„λ” 5x5 1κ° λ³΄λ‹¤ 3x3μ„ 2κ° ν™μ©ν•λ”κ² νλΌλ―Έν„° μλ¥Ό μ¤„μΌ μ μμ.**

β†’ λ”°λΌμ„ λ’¤μ— λ‚μ¤λ” λ€λ¶€λ¶„μ λ…Όλ¬Έλ“¤μ—μ„ conv ν•„ν„°(μ»¤λ„) μ special dimension μ€ 7x7 μ„ λ²—μ–΄λ‚μ§€ μ•μ. μ»¤λ΄¤μ 5x5 μ΄λ‹¤. λΉ„μ·ν• μ΄μ λ΅.

- GoogLeNet(2015)

![Untitled](/assets/images/DL_basic/Untitled%2042.png)

- 1x1 conv μ€ dimension reduction μ ν¨κ³Όκ°€ μκ³  μ—¬κΈ°μ„ λ§ν•λ” dimension μ€ channel. κ·Έλμ„ μ»¨λ³Όλ£¨μ… ν”Όμ³λ§µμ΄ special dimension(W & H) μ΄ μλ”λ° κ·Έκ² μ•„λ‹λΌ κ·Έ μ΄λ―Έμ§€ tensorμ depth λ°©ν–¥μ— ν•΄λ‹Ήν•λ” channel μ„ μ¤„μ΄λ” κ²ƒ.
- μ΄κ²ƒμ€ λ„¤νΈμ›ν¬λ¥Ό λ‘κ°™μ΄ λ”¥ν•κ² μ“μ•„λ„ μ¤‘κ°„μ— 1x1 conv λ¥Ό μ ν™μ©ν•λ©΄ νλΌλ―Έν„° μ«μλ¥Ό μ¤„μΌ μ μκ² λ¨.
- AlexNet β†’ VGGNet μ—μ„λ” 11x11, 5x5, 7x7 λ³΄λ‹¤λ” input λ‹¨μ special receptive field λ¥Ό λλ¦¬λ” μ°¨μ›μ—μ„λ” 3x3 μ„ μ—¬λ¬λ² ν™μ©ν•λ” κ²ƒμ΄ μΆ‹λ‹¤λ” κ²ƒμ„ μ•κ² λ¨.
- GoogLeNet μ—μ„λ” 1x1 conv λ¥Ό μ ν™μ©ν•΄μ„ μ „μ²΄μ μΈ νλΌλ―Έν„° μλ¥Ό μ¤„μΌ μ μλ”μ§€λ¥Ό λ³Ό μ μμ.
- λΉ„μ·ν•κ² λ³΄μ΄λ” λ„¤νΈμ›ν¬κ°€ λ°λ³µλ¨. λ„¤νΈμ›ν¬ λ¨μ–‘μ΄ λ„¤νΈμ›ν¬ μ•μ— μλ‹¤κ³  ν•΄μ„ NIN(Network In Network) κµ¬μ΅°λΌκ³  ν•¨.

![Untitled](/assets/images/DL_basic/Untitled%2043.png)

- Inception block? ν•λ‚μ μ…λ ¥μ΄ λ“¤μ–΄μ™”μ„ λ• νΌμ΅λ‹¤κ°€ ν•©μ³μ§. μ¤‘μ”ν• κ²ƒμ€, κ°κ°μ path λ¥Ό λ³΄λ©΄ 3x3 conv λ¥Ό ν•κΈ° μ „μ— 1x1 Conv κ°€ λ“¤μ–΄κ°. μ¦‰ Convolution filter μ „μ— 1x1 μ΄ λ“¤μ–΄κ°€λ” κ²ƒ. μ΄κ² μ¤‘μ”ν• μ—­ν• μ„ ν•¨.
- μ™ μ¤‘μ”ν• κΉ? ν•λ‚μ μ…λ ¥μ— λ€ν•΄μ„ μ—¬λ¬κ°μ receptive field λ¥Ό κ°–λ” ν•„ν„°λ¥Ό κ±°μΉκ³  μ΄κ²ƒμ„ ν†µν•΄μ„ μ—¬λ¬κ°μ repsonse λ“¤μ„ concatenation ν•λ” ν¨κ³Όλ„ μμ§€λ§, μ—¬κΈ°μ„ 1x1 conv μ΄ μ¤‘κ°„μ— μμμΌλ΅μ„ μ „μ²΄ λ„¤νΈμ›ν¬μ νλΌλ―Έν„° μλ¥Ό μ¤„μ„.
- μ–΄λ–»κ² νλΌλ―Έν„° μ«μλ¥Ό μ¤„μ΄λ” κ²ƒμΌκΉ? β†’ κ·Έλ¬λ©΄ μ΄ 1x1 conv μ΄ μ™ μ¤‘μ”ν•μ§€λ¥Ό μ• μ μμ.

β†’ 1x1 conv can be seen as channel-wise dimension reduction ; μ±„λ„ λ°©ν–¥μΌλ΅ μ¤„μΈλ‹¤!


![Untitled](/assets/images/DL_basic/Untitled%2044.png)

- μ•μ—μ„ 5x5 λ³΄λ‹¤ 3x3μ΄ λ” νλΌλ―Έν„° μλ¥Ό μ¤„μΌ μ μμ—μ. κ²°κ³Όμ μΌλ΅ 3x3 μ΄ μ°λ¦¬κ°€ μ¤„μΌ μ μλ” μµμ†ν•μΈλ°, μ—¬κΈ°μ„ 1x1 μ„ ν†µν•΄μ„ λ” νλΌλ―Έν„° μλ¥Ό μ¤„μ΄λ” κ²ƒ.
- μ¤‘κ°„μ— 1x1 conv μ„ ν†µν•΄μ„ special dimesion μ€ κ·Έλ€λ΅ κ°€κ³  μ±„λ„ λ°©ν–¥μΌλ΅ μ •λ³΄λ¥Ό μ¤„μΈ κ²ƒ. μ΄λ ‡κ² μ¤„μ΄κ³  μ–»μ–΄μ§€λ” β€μ–΄λ–¤ μ¤„μ–΄λ“  μ±„λ„μ„ κ°€μ§„ special dimension μ conv feature mapβ€™μ— 3x3 conv λ¥Ό ν•λ” κ²ƒ. μ΄λ ‡κ² λ§λ“¤μ–΄μ§„ 2layer μ νλΌλ―Έν„° μ«μλ” λ” μ¤„μ–΄λ“¦.
- κ·Έλμ„ μ…λ ¥κ³Ό μ¶λ ¥λ§ λ΄¤μ„ λ• μ±„λ„μ€ λ‘κ°™μ. λν• receptive field λ„ κ°™μ. 3x3 λ¥Ό μ‚¬μ©ν–κΈ° λ•λ¬Έ. κ·Έλ°λ° νλΌλ―Έν„° μ«μκ°€ λ§μ΄ μ¤„μ–΄λ“¦. μ΄λ° 1x1 conv μ„ ν†µν•΄ μ±„λ„ λ°©ν–¥μΌλ΅ dimension reduction μ΄ λ“¤μ–΄κ°€λ©΄μ„ μ „μ²΄μ μΈ νλΌλ―Έν„° μ«μλ” μ¤„μ–΄λ“¦. λν• μ…λ ¥κ³Ό μ¶λ ¥λ§ λ†“κ³  λ³΄λ©΄ receptive field λ” λ‘κ°™κ³  μ…λ ¥κ³Ό μ¶λ ¥μ μ±„λ„ λν• κ°™μ.

![Untitled](/assets/images/DL_basic/Untitled%2045.png)

- GoogLeNet μ€ VGGNet μ— λΉ„ν•΄μ„ νλΌλ―Έν„° μκ°€ μ—„μ²­ μ¤„μ–΄λ“¦. λ„¤νΈμ›ν¬λ” 3λ‹¨ κΉμ–΄μ§. μ΄κ² λ°”λ΅ λ’·λ‹¨μ dense layerλ¥Ό μ¤„μ΄κ³ , 11x11 λ¥Ό μ¤„μ΄κ³  1x1 conv λ΅ feature dimension μ„ μ¤„μ΄κΈ° λ•λ¬Έ. β†’ μ¦‰ λ„¤νΈμ›ν¬λ” μ μ  κΉμ–΄μ§€κ³  νλΌλ―Έν„° μλ” μ¤„μ–΄λ“¤κ³  μ„±λ¥μ€ μΆ‹μ•„μ§!!
- ResNet (2015)
- Generalization performance - train error κ°€ μ¤„μ–΄λ“¦μ—λ„ λ¶κµ¬ν•κ³  test error μ™€ μ°¨μ΄κ°€ λ§μ΄ λ‚λ” μ •λ„λ¥Ό μλ―Έ β†’ μ°¨μ΄κ°€ μ μ–΄μ•Ό μΌλ°ν™” μ„±λ¥μ΄ μΆ‹λ‹¤!
- νλΌλ―Έν„° μκ°€ λ§μ€ κ²ƒμ€ 1) μ¤λ²„ν”Όν… λ¬Έμ κ°€ μμ. 2)
- μ¤λ²„ν”Όν…μ€ ν•™μµ μ—λ¬κ°€ μ¤„μ–΄λ“λ”λ° ν…μ¤νΈ μ—λ¬κ°€ μ»¤μ§€λ” κ²ƒ. μ¬λ΅ν”„κ°€ λ°λ€λλ” κ²ƒ. ν…μ¤νΈ μ—λ¬κ°€ μ μ  μ»¤μ§€λ” κ²ƒ. μ•„λ κ·Έλ¦Όμ€ μ¤λ²„ν”Όν…μ€ μ•„λ‹. λ‘ λ‹¤ κ°™μ΄ μ¤„μ–΄λ“¤μ—κΈ° λ•λ¬Έ.

![Untitled](/assets/images/DL_basic/Untitled%2046.png)

- λ¬Έμ λ” ν•™μµ μ—λ¬κ°€ μ‘μμ—λ„ λ¶κµ¬ν•κ³  ν…μ¤νΈ μ—λ¬κ°€ λ” ν° κ²ƒ. μ¦‰ ν•™μµμ΄ μ•λλ” κ²ƒ.
56 λ μ΄μ–΄λ¥Ό μ•„λ¬΄λ¦¬ μ ν•™μµμ‹μΌλ΄¤μ 20λ μ΄μ–΄κ°€ λ” ν•™μµμ΄ μλλ” κ²ƒ.
β†’ μ¤λ²„ν”Όν…μ€ μ•„λ‹μ§€λ§ λ„¤νΈμ›ν¬κ°€ μ»¤μ§μ— λ”°λΌμ„ ν•™μµμ„ λ» μ‹ν‚¤λ” κ²ƒ.
- κ·Έλμ„ ResNet μ€ residual connection(identity map νΉμ€ skip connection)μ„ μ¶”κ°€ν•¨.

![Untitled](/assets/images/DL_basic/Untitled%2047.png)

- skip connection μ€ μ…λ ¥μ΄ μ¬λΌκ°€λ©΄ μ¶λ ¥μ΄ λ‚μ¤λ”λ°, κ·Έ μ…λ ¥μ„ λ‰΄λ΄ λ„¤νΈμ›ν¬μ μ¶λ ¥ κ°’ νΉμ€ ν•λ‹¨ μ§λ¦¬ conv layer μ— λ”ν•΄μ£Όλ” κ²ƒ.
β†’ κ¶κ·Ήμ μΌλ΅ μ›ν•λ” κ²ƒμ€ μ΄ conv layer κ°€ ν•™μµν•κ³ μ ν•λ” κ²ƒμ€ residual. μ°¨μ΄λ§ ν•™μµν•λ” κ²ƒ. μ™λƒλ©΄ xμ—λ‹¤κ°€ f(x)λ¥Ό λ”ν–κΈ° λ•λ¬Έ. μ‹¤μ λ΅ f(x)κ°€ ν•™μµν•λ” κ²ƒμ€ κ·Έ μ°¨μ΄λ¥Ό ν•™μµν•κΈΈ μ›ν•λ” κ²ƒ. κ·Έλ ‡κ² λλ©΄ μ•„λμ²λΌ κΉμ–΄μ΅μ„ λ• ν•™μµμ΄ μ λ  μ μμ.

β‡’ **skip connectionμ΄ gradient μ†μ‹¤ λ¬Έμ  ν•΄κ²°μ—λ„ λ„μ›€μ΄ λλ”λ°, Skip Connectionμ€ κ·Έλλ””μ–ΈνΈκ°€ μ§μ ‘μ μΌλ΅ λ’¤λ΅ μ „λ‹¬λ  μ μλ„λ΅ ν•μ—¬ κ·Έλλ””μ–ΈνΈ μ†μ‹¤ λ¬Έμ λ¥Ό μ™„ν™”ν•λ‹¤.**

![Untitled](/assets/images/DL_basic/Untitled%2048.png)

- identity map μ„ μ‚¬μ©ν•λ©΄ **ν•™μµ μμ²΄**λ¥Ό λ” μ μ‹ν‚¬ μ μκ² λλ” κ²ƒ. λ„¤νΈμ›ν¬λ¥Ό λ”¥ν•κ² μ“μ„ μ μλ” κ°€λ¥μ„±μ„ μ—΄μ–΄μ¤€ κ²ƒ. κΉκ² μ“μ•„λ„ ν•™μµ κ°€λ¥!

![Untitled](/assets/images/DL_basic/Untitled%2049.png)

- μ¤‘μ”ν• μ μ€, x λ¥Ό λ”ν•λ ¤λ©΄ μ°¨μ›μ΄ κ°™μ•„μ•Ό ν•¨. λ‚΄κ°€ μ…λ ¥μ΄ 128x128x64 μΌ λ•, 3x3conv - BN - ReLU - 3x3conv - BN μ„ ν†µκ³Όν•κ³  λ‚μ¨ κ°’μ΄ μ—­μ‹ 128x128x64 κ°€ λμ–΄μ•Ό ν•¨.
- μ°¨μ›μ„ λ§μ¶°μ£ΌκΈ° μ„ν•΄μ„ 1x1 conv λ΅ μ±„λ„μ„ λ°”κΏ”μ£Όλ” κ²ƒμ΄ projected Shortcut
- μ¬λ°λ” κ²ƒμ€, BN μ΄ μ»¨λ³Όλ£¨μ… λ’¤μ— μΌμ–΄λ‚κ² λ¨. κ·Έ λ‹¤μμ— activation μ΄ μΌμ–΄λ‚¨.
- BN μ„ ReLU λ‹¤μμ— λ„£μ–΄μ•Ό μλλ‹¤, μ•λ„£μ–΄μ•Ό μλλ‹¤ μ΄λ° λ§λ“¤λ„ μμ. μ›λ λ…Όλ¬Έμ—μ„λ” BN μ΄ Conv λ‹¤μμ— λ‚μ΄.

![Untitled](/assets/images/DL_basic/Untitled%2050.png)

- μ—¬κΈ°λ„ Bottleneck arch κ°€ λ‚μ΄. 3x3 conv λ¥Ό μ„ν•΄μ„λ” νλΌλ―Έν„° μλ” 3 x 3 x input_channel x output_channel. λ‚΄κ°€ 3x3 conv ν•κΈ° μ „μ— input_channel μ„ μ¤„μ΄λ©΄ μ „μ²΄μ μΈ νλΌλ―Έν„° μλ¥Ό μ¤„μΌ μ μμ. κ·Έλμ„ **3x3 conv μ „μ— input μ±„λ„μ„ μ¤„μ΄κ³ , 3x3 conv μ΄ν›„μ— input μ±„λ„μ„ λλ¦¬λ” μ©λ„λ΅ 1x1 conv κ°€ μ‚¬μ©λ¨**. κ·Έλμ„ 1x1 conv μ΄ 2λ² λ“¤μ–΄κ°€λ” κ²ƒ. μ΄κ²ƒμ„ ν†µν•΄μ„ λ‚΄κ°€ κ¶κ·Ήμ μΌλ΅ μ›ν•λ” output conv feature map μ μ±„λ„μ μ°¨μ›μ„ λ§μ¶ μ μλ” κ²ƒ.

β‡’ μ •λ¦¬ν•λ©΄, 1x1 conv λ¥Ό μ΄μ©ν•΄μ„ μ±„λ„μ„ μ¤„μ΄κ² λκ³ , κ·Έλ ‡κ² μ¤„μ–΄λ“  μ±„λ„μ—μ„ 3x3 conv μ„ ν•¨μΌλ΅μ¨ receptive field λ¥Ό ν‚¤μ°κ³ , λ‹¤μ‹ 1x1 conv λ΅ μ›ν•λ” μ±„λ„μ„ λ§μ¶°μ£Όλ” ν…ν¬λ‹‰. μ΄λ° μ‹μΌλ΅ νλΌλ―Έν„° μ«μλ” μ¤„μ„κ³Ό λ™μ‹μ— λ„¤νΈμ›ν¬λ¥Ό κΉκ² μ“μ•„μ„ receptive field λ¥Ό ν‚¤μ°λ” κ² μ „λµ.

- DenseNet (2017)
- μ•„μ΄λ””μ–΄κ°€ κ°„λ‹¨ν•¨. ResNet μ„ high-level view μ—μ„ λ°”λΌλ³΄κ² λλ©΄ convμ„ ν†µν•΄μ„ λ‚μ¤λ” κ°’μ„ κ·Έλƒ¥ λ”ν•λ” κ²ƒ(μΈν’‹μ„). μ—¬κΈ°μ„ λ‘ κ°κ°€ μ„μ΄λ‹κΉ λ”ν•μ§€ λ§κ³ , special dimension μ΄ κ°™μΌλ‹κΉ λ‘ κ°λ¥Ό concatenation ν•μ! λ” κ²ƒ.

![Untitled](/assets/images/DL_basic/Untitled%2051.png)

- concatenate ν•  λ• λ¬Έμ λ” μ±„λ„μ΄ μ μ  μ»¤μ§. μ±„λ„μ΄ κΈ°ν•κΈ‰μμ μΌλ΅ μ»¤μ§. μ™λƒν•λ©΄ λ’¤μ— μλ” κ²ƒμ€ μ•μ— μλ” λ¨λ“  μ±„λ„μ„ λ‹¤ concatenate ν–κΈ° λ•λ¬Έ(κ°’μ„ λ”ν•λ” κ² μ•„λ‹ λ¶™νλ” κ²ƒ!).

![Untitled](/assets/images/DL_basic/Untitled%2052.png)

- κ·Έλμ„ μ±„λ„μ΄ μ»¤μ§€λ©΄, κ±°κΈ°μ„ κ°€ν•΄μ§€λ” conv feature map μ μ±„λ„λ„ κ°™μ΄ μ»¤μ§. λ”°λΌμ„ νλΌλ―Έν„° μλ„ κ°™μ΄ μ»¤μ§. κ·Έλμ„ μ°λ¦¬κ°€ μ›ν•λ” κ²ƒμ€, μ¤‘κ°„μ— ν•λ²μ”© μ±„λ„μ„ μ¤„μ—¬μ•Ό ν•¨. μ¦‰ νλΌλ―Έν„° μλ¥Ό μ¤„μ—¬μ•Ό ν•¨. β†’ μ—¬κΈ°μ„ 1x1 conv κ°€ μ‚¬μ©λ¨.
- Dense Block
- feature map μ„ κ³„μ† ν‚¤μ°λ” κ²ƒ(concate)
- Transition Block
- BN β†’ 1x1 conv β†’ 2x2 AvgPooling
- 1x1 conv μ—μ„ conv feature map size λ¥Ό ν™• μ¤„μ„. λ‹¤μ‹ Dense Block μΌλ΅ μ­‰ λμ„. κ·Έλ¦¬κ³  λ‹¤μ‹ Transition Block μΌλ΅ μ­‰ μ¤„μ„. κ³„μ† λ°λ³µν•λ” κ²ƒμ΄ DenseNet

![Untitled](/assets/images/DL_basic/Untitled%2053.png)

β‡’ receptive field λ¥Ό λλ¦¬λ” μ…μ¥μ—μ„λ” VGG

β‡’ GoogLeNet μ—μ„ 1x1 conv λ΅ μ±„λ„ μλ¥Ό μ¤„μ—¬μ„ νλΌλ―Έν„° μλ¥Ό μ¤„μ„.

β‡’ ResNet μ—μ„ skip connection μΌλ΅ λ„¤νΈμ›ν¬λ¥Ό κΉκ² μ“μ„ μ μκ² ν•¨.

β‡’ DenseNetμ—μ„λ” concatenation μΌλ΅ ν”Όμ³λ§µμ„ λ”ν•λ” κ²ƒ λ€μ‹ μ— μ“μΌλ©΄μ„ λ” μΆ‹μ€ μ„±λ¥μ„ λ‚Ό μ μμ—λ‹¤λ” κ²ƒ.